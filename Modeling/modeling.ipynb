{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title : Data Cleaning + Base Model\n",
    "# Author : Alex Bass\n",
    "# Date : 27 March 2023\n",
    "\n",
    "import pandas as pd\n",
    "from thefuzz import fuzz\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model, ensemble, neighbors\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# - - - - - - - - - - - #\n",
    "# Cleaning before modeling\n",
    "# - - - - - - - - - - - #\n",
    "\n",
    "def get_lev_distance_or_NA(data, columns, partial = False, sort = False):\n",
    "    assert isinstance(data, pd.DataFrame)\n",
    "    assert isinstance(columns, list)\n",
    "    assert len(columns) == 2\n",
    "    #If partial is True, First column will be fully matched, Second column partially matched\n",
    "    assert isinstance(columns[0], str)\n",
    "    assert isinstance(columns[1], str)\n",
    "    \n",
    "    out = []\n",
    "    for i in range(data.shape[0]):\n",
    "        val1 = data[columns[0]].iloc[i]\n",
    "        val2 = data[columns[1]].iloc[i]\n",
    "        if pd.isna(val1) or val1 == \"\" or pd.isna(val2) or val2 == \"\":\n",
    "            out.append(np.nan)\n",
    "        else:\n",
    "            if partial and sort:\n",
    "                out.append(fuzz.partial_token_sort_ratio(val1, val2))\n",
    "            elif partial:\n",
    "                out.append(fuzz.partial_ratio(val1, val2))\n",
    "            elif sort:\n",
    "                out.append(fuzz.token_sort_ratio(val1, val2))\n",
    "            else:\n",
    "                out.append(fuzz.ratio(val1, val2))\n",
    "    return out\n",
    "\n",
    "train = pd.read_csv(\"training_set_final.csv\")\n",
    "test = pd.read_csv(\"golden_set.csv\")\n",
    "\n",
    "#lev distance for title\n",
    "train['title_match'] = get_lev_distance_or_NA(train, ['title_ia', 'title_wiki'])\n",
    "test['title_match'] = get_lev_distance_or_NA(test, ['title_ia', 'title_wiki'])\n",
    "\n",
    "# using partial matching because title_ia is usually more descriptive\n",
    "train['title_match_partial'] = get_lev_distance_or_NA(train, ['title_wiki', 'title_ia'], partial = True, sort = True)\n",
    "test['title_match_partial'] = get_lev_distance_or_NA(test, ['title_wiki', 'title_ia'], partial = True, sort = True)\n",
    "\n",
    "#for author\n",
    "train.author_ia = train.author_ia.astype('str')\n",
    "train.author_wiki = train.author_wiki.astype('str')\n",
    "\n",
    "test.author_ia = test.author_ia.astype('str')\n",
    "test.author_wiki = test.author_wiki.astype('str')\n",
    "\n",
    "for var in ['author_ia', 'author_wiki']:\n",
    "    train[var] = train[var].replace({'nan': np.nan})\n",
    "    test[var] = test[var].replace({'nan': np.nan})\n",
    "\n",
    "train['author_match'] = get_lev_distance_or_NA(train, ['author_ia', 'author_wiki'])\n",
    "test['author_match'] = get_lev_distance_or_NA(test, ['author_ia', 'author_wiki'])\n",
    "\n",
    "train['author_sort'] = get_lev_distance_or_NA(train, ['author_ia', 'author_wiki'], sort = True)\n",
    "test['author_sort'] = get_lev_distance_or_NA(test, ['author_ia', 'author_wiki'], sort = True)\n",
    "\n",
    "#for publisher\n",
    "train['publisher_match'] = get_lev_distance_or_NA(train, ['publisher_ia', 'publisher_wiki'])\n",
    "test['publisher_match'] = get_lev_distance_or_NA(test, ['publisher_ia', 'publisher_wiki'])\n",
    "\n",
    "# using partial matching because publisher_ia is usually more descriptive\n",
    "train['publisher_match_partial'] = get_lev_distance_or_NA(train, ['publisher_wiki', 'publisher_ia'], partial = True)\n",
    "test['publisher_match_partial'] = get_lev_distance_or_NA(test, ['publisher_wiki', 'publisher_ia'], partial = True)\n",
    "\n",
    "#year\n",
    "def clean(string):\n",
    "    if pd.isna(string):\n",
    "        return np.nan\n",
    "    string = str(string)\n",
    "    if any(char.isdigit() for char in string) == False:\n",
    "        return np.nan\n",
    "    string = re.subn(r'\\.[0-9]+',\"\",string)[0]\n",
    "    string = re.subn(r'\\.',\"\",string)[0]\n",
    "    if string:\n",
    "        try:\n",
    "            return int(''.join(filter(str.isdigit, string)))\n",
    "        except:\n",
    "            print(string)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "train.year_wiki = train.year_wiki.apply(clean)\n",
    "train.date_ia = train.date_ia.apply(clean)\n",
    "test.year_wiki = test.year_wiki.apply(clean)\n",
    "test.date_ia = test.date_ia.apply(clean)\n",
    "\n",
    "year_res = []\n",
    "for i in range(train.shape[0]):\n",
    "    val1 = train.date_ia.iloc[i]\n",
    "    val2 = train.year_wiki.iloc[i]\n",
    "    if val1 and val2:\n",
    "        year_res.append(float(val1) == float(val2))\n",
    "    else:\n",
    "        year_res.append(np.nan)\n",
    "\n",
    "train['year_match'] = year_res\n",
    "        \n",
    "year_res = []\n",
    "for i in range(test.shape[0]):\n",
    "    val1 = test.date_ia.iloc[i]\n",
    "    val2 = test.year_wiki.iloc[i]\n",
    "    if val1 and val2:\n",
    "        year_res.append(float(val1) == float(val2))\n",
    "    else:\n",
    "        year_res.append(np.nan)\n",
    "        \n",
    "test['year_match'] = year_res\n",
    "\n",
    "#year NA\n",
    "train['year_NA'] = [np.where(pd.isna(train.year_wiki.iloc[i]) or pd.isna(train.date_ia.iloc[i]), 1, 0) for i in range(train.shape[0])]\n",
    "test['year_NA'] = [np.where(pd.isna(test.year_wiki.iloc[i]) or pd.isna(test.date_ia.iloc[i]), 1, 0) for i in range(test.shape[0])]\n",
    "\n",
    "#Author NA\n",
    "train['author_NA'] = [np.where(pd.isna(train.author_ia.iloc[i]) or pd.isna(train.author_wiki.iloc[i]), 1, 0) for i in range(train.shape[0])]\n",
    "test['author_NA'] = [np.where(pd.isna(test.author_ia.iloc[i]) or pd.isna(test.author_wiki.iloc[i]),1, 0) for i in range(test.shape[0])]\n",
    "\n",
    "#Publisher NA\n",
    "train['publisher_NA'] = [np.where(pd.isna(train.publisher_ia.iloc[i]) or pd.isna(train.publisher_wiki.iloc[i]), 1, 0) for i in range(train.shape[0])]\n",
    "test['publisher_NA'] = [np.where(pd.isna(test.publisher_ia.iloc[i]) or pd.isna(test.publisher_wiki.iloc[i]), 1, 0) for i in range(test.shape[0])]\n",
    "\n",
    "#downsampling\n",
    "has_match = train.groupby('query_count')['citebook_match'].transform(lambda x : any(x == 1)).to_list()\n",
    "train = train[has_match]\n",
    "\n",
    "tmp_match = train.query('citebook_match == 1')\n",
    "tmp_unmatch = train.query('citebook_match == 0') \\\n",
    "    .groupby('query_count') \\\n",
    "    .sample(1)\n",
    "train = pd.concat([tmp_match, tmp_unmatch], ignore_index = True)\n",
    "\n",
    "train = shuffle(train)\n",
    "\n",
    "#store NA data for later\n",
    "train_w_NAs = train\n",
    "test_w_NAs = test\n",
    "\n",
    "# replace missing values with mean\n",
    "for var in ['title_match','author_match', 'publisher_match', 'year_match', 'title_match_partial', 'publisher_match_partial', 'author_sort']:\n",
    "    train[var] = train[var].fillna(train[var].mean())\n",
    "    test[var] = test[var].fillna(test[var].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data\n",
    "train_x = train[['title_match','author_match', 'publisher_match', 'year_match', 'year_NA', 'author_NA', 'publisher_NA', 'title_match_partial', 'publisher_match_partial', 'author_sort']]\n",
    "train_y = train['citebook_match']\n",
    "test_x = test[['title_match','author_match', 'publisher_match', 'year_match', 'year_NA', 'author_NA', 'publisher_NA', 'title_match_partial', 'publisher_match_partial', 'author_sort']]\n",
    "test_y = test['citebook_match']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "test_x = scaler.transform(test_x)\n",
    "\n",
    "def get_model_results(model_name, model, param_grid, cv, train_x, train_y, test_x, test_y, save = False):\n",
    "    \n",
    "    time1 = time.time()\n",
    "    \n",
    "    if cv == 1:\n",
    "        search = model.fit(train_x, train_y)\n",
    "        best_params = \"\"\n",
    "        \n",
    "    else:\n",
    "        search = GridSearchCV(model, param_grid, cv=cv, scoring=('precision', 'recall', 'accuracy'), refit='accuracy')\n",
    "        search.fit(train_x, train_y)\n",
    "\n",
    "    y_train_hat = search.predict(train_x)\n",
    "    y_train_hat_probs = search.predict_proba(train_x)[:,1]\n",
    "\n",
    "    train_accuracy = accuracy_score(train_y, y_train_hat)*100\n",
    "    train_precision = precision_score(train_y, y_train_hat)*100\n",
    "    train_recall = recall_score(train_y, y_train_hat)*100\n",
    "    train_auc_roc = roc_auc_score(train_y, y_train_hat_probs)*100\n",
    "\n",
    "    y_test_hat = search.predict(test_x)\n",
    "    y_test_hat_probs = search.predict_proba(test_x)[:,1]\n",
    "\n",
    "    test_accuracy = accuracy_score(test_y, y_test_hat)*100\n",
    "    test_precision = precision_score(test_y, y_test_hat)*100\n",
    "    test_recall = recall_score(test_y, y_test_hat)*100\n",
    "    test_auc_roc = roc_auc_score(test_y, y_test_hat_probs)*100\n",
    "    \n",
    "    if cv != 1:\n",
    "        best_params = str(search.best_params_)\n",
    "\n",
    "    res = {\n",
    "        'model_name' : model_name,\n",
    "        'Training Accuracy' : train_accuracy,\n",
    "        'Training Precision' : train_precision,\n",
    "        'Training Recall' : train_recall,\n",
    "        'Test Accuracy' : test_accuracy,\n",
    "        'Test Precision' : test_precision,\n",
    "        'Test Recall' :test_recall,\n",
    "        'Best Params' : best_params\n",
    "    }\n",
    "    \n",
    "    time2 = time.time()\n",
    "    time_elapsed = round((time2 - time1)/60, 2)\n",
    "    \n",
    "    print(f'For the {model_name} model, the time elapsed is {time_elapsed} minutes.')\n",
    "    \n",
    "    if save and cv == 1: # only save when applied to all the data\n",
    "        filename = 'finalized_model.sav'\n",
    "        pickle.dump(search, open(filename, 'wb'))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the Logistic Regression model, the time elapsed is 0.11 minutes.\n"
     ]
    }
   ],
   "source": [
    "# - - - - - - - - - - - #\n",
    "# Logistic Regression\n",
    "# - - - - - - - - - - - #\n",
    "\n",
    "model_name = \"Logistic Regression\"\n",
    "\n",
    "model = linear_model.LogisticRegression(solver = 'saga', max_iter = 150) #saga supports all types of model penalties\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l2' ,'l1',None]\n",
    "}\n",
    "\n",
    "res = get_model_results(model_name, model, param_grid, 5, train_x, train_y, test_x, test_y)\n",
    "\n",
    "res = pd.DataFrame(res, index=[0])\n",
    "\n",
    "if 'final_res' not in locals():\n",
    "    final_res = res\n",
    "else:\n",
    "    final_res = pd.concat([final_res, res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the Random Forest Clasifier model, the time elapsed is 36.04 minutes.\n"
     ]
    }
   ],
   "source": [
    "# - - - - - - - - - - - #\n",
    "# Random Forest\n",
    "# - - - - - - - - - - - #\n",
    "\n",
    "model = ensemble.RandomForestClassifier()\n",
    "model_name = \"Random Forest Clasifier\"\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 500],\n",
    "    'max_depth' : [None, 3, 5],\n",
    "    'max_features' : [2, 3, 4, 5, None]\n",
    "}\n",
    "\n",
    "res = get_model_results(model_name, model, param_grid, 5, train_x, train_y, test_x, test_y)\n",
    "\n",
    "res = pd.DataFrame(res, index=[0])\n",
    "\n",
    "if 'final_res' not in locals():\n",
    "    final_res = res\n",
    "else:\n",
    "    final_res = pd.concat([final_res, res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the KNeighbors model, the time elapsed is 1.56 minutes.\n"
     ]
    }
   ],
   "source": [
    "# - - - - - - - - - - - #\n",
    "# K Neighbors\n",
    "# - - - - - - - - - - - #\n",
    "\n",
    "model = neighbors.KNeighborsClassifier()\n",
    "model_name = \"KNeighbors\"\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 10, 25]\n",
    "}\n",
    "\n",
    "res = get_model_results(model_name, model, param_grid, 5, train_x, train_y, test_x, test_y)\n",
    "\n",
    "res = pd.DataFrame(res, index=[0])\n",
    "\n",
    "if 'final_res' not in locals():\n",
    "    final_res = res\n",
    "else:\n",
    "    final_res = pd.concat([final_res, res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bringing back data w NAs with GBT which handles these\n",
    "train = train_w_NAs\n",
    "test = test_w_NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the GBT model, the time elapsed is 2.48 minutes.\n"
     ]
    }
   ],
   "source": [
    "# - - - - - - - - - - - #\n",
    "# Gradient Boosted Tree Model w NAs\n",
    "# - - - - - - - - - - - #\n",
    "\n",
    "#Model with all data\n",
    "train_x = train[['title_match','author_match', 'publisher_match', 'year_match', 'year_NA', 'author_NA', 'publisher_NA', 'title_match_partial', 'publisher_match_partial', 'author_sort']]\n",
    "train_y = train['citebook_match']\n",
    "test_x = test[['title_match','author_match', 'publisher_match', 'year_match', 'year_NA', 'author_NA', 'publisher_NA', 'title_match_partial', 'publisher_match_partial', 'author_sort']]\n",
    "test_y = test['citebook_match']\n",
    "\n",
    "model = ensemble.HistGradientBoostingClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.2, 0.5],\n",
    "    'max_depth' : [None, 3, 5],\n",
    "    'l2_regularization' : [0, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "res = get_model_results(\"GBT\", model, param_grid, 5, train_x, train_y, test_x, test_y)\n",
    "\n",
    "res = pd.DataFrame(res, index=[0])\n",
    "\n",
    "if 'final_res' not in locals():\n",
    "    final_res = res\n",
    "else:\n",
    "    final_res = pd.concat([final_res, res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the GBT - default model, the time elapsed is 0.09 minutes.\n"
     ]
    }
   ],
   "source": [
    "param_grid = {}\n",
    "\n",
    "res = get_model_results(\"GBT - default\", model, param_grid, 5, train_x, train_y, test_x, test_y)\n",
    "\n",
    "res = pd.DataFrame(res, index=[0])\n",
    "\n",
    "if 'final_res' not in locals():\n",
    "    final_res = res\n",
    "else:\n",
    "    final_res = pd.concat([final_res, res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Training Precision</th>\n",
       "      <th>Training Recall</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GBT - default</td>\n",
       "      <td>85.556595</td>\n",
       "      <td>84.164820</td>\n",
       "      <td>94.713135</td>\n",
       "      <td>98.943197</td>\n",
       "      <td>95.238095</td>\n",
       "      <td>95.238095</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>83.185246</td>\n",
       "      <td>82.886433</td>\n",
       "      <td>92.119578</td>\n",
       "      <td>98.282695</td>\n",
       "      <td>94.936709</td>\n",
       "      <td>89.285714</td>\n",
       "      <td>{'penalty': 'l2'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Clasifier</td>\n",
       "      <td>92.307243</td>\n",
       "      <td>91.038527</td>\n",
       "      <td>97.267725</td>\n",
       "      <td>97.490092</td>\n",
       "      <td>94.520548</td>\n",
       "      <td>82.142857</td>\n",
       "      <td>{'max_depth': None, 'max_features': 4, 'n_esti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Clasifier</td>\n",
       "      <td>92.307243</td>\n",
       "      <td>91.038527</td>\n",
       "      <td>97.267725</td>\n",
       "      <td>97.490092</td>\n",
       "      <td>94.520548</td>\n",
       "      <td>82.142857</td>\n",
       "      <td>{'max_depth': None, 'max_features': 4, 'n_esti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GBT</td>\n",
       "      <td>87.827595</td>\n",
       "      <td>86.226143</td>\n",
       "      <td>95.835347</td>\n",
       "      <td>98.414795</td>\n",
       "      <td>91.860465</td>\n",
       "      <td>94.047619</td>\n",
       "      <td>{'l2_regularization': 0.1, 'learning_rate': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>87.939635</td>\n",
       "      <td>88.008691</td>\n",
       "      <td>93.436618</td>\n",
       "      <td>96.961691</td>\n",
       "      <td>85.882353</td>\n",
       "      <td>86.904762</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model_name  Training Accuracy  Training Precision  \\\n",
       "0            GBT - default          85.556595           84.164820   \n",
       "0      Logistic Regression          83.185246           82.886433   \n",
       "0  Random Forest Clasifier          92.307243           91.038527   \n",
       "0  Random Forest Clasifier          92.307243           91.038527   \n",
       "0                      GBT          87.827595           86.226143   \n",
       "0               KNeighbors          87.939635           88.008691   \n",
       "\n",
       "   Training Recall  Test Accuracy  Test Precision  Test Recall  \\\n",
       "0        94.713135      98.943197       95.238095    95.238095   \n",
       "0        92.119578      98.282695       94.936709    89.285714   \n",
       "0        97.267725      97.490092       94.520548    82.142857   \n",
       "0        97.267725      97.490092       94.520548    82.142857   \n",
       "0        95.835347      98.414795       91.860465    94.047619   \n",
       "0        93.436618      96.961691       85.882353    86.904762   \n",
       "\n",
       "                                         Best Params  \n",
       "0                                                 {}  \n",
       "0                                  {'penalty': 'l2'}  \n",
       "0  {'max_depth': None, 'max_features': 4, 'n_esti...  \n",
       "0  {'max_depth': None, 'max_features': 4, 'n_esti...  \n",
       "0  {'l2_regularization': 0.1, 'learning_rate': 0....  \n",
       "0                                 {'n_neighbors': 5}  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_res.sort_values(\"Test Precision\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the GBT - default model, the time elapsed is 0.03 minutes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'GBT - default',\n",
       " 'Training Accuracy': 85.54003234543364,\n",
       " 'Training Precision': 84.07611624725342,\n",
       " 'Training Recall': 94.82691438457582,\n",
       " 'Test Accuracy': 99.20739762219286,\n",
       " 'Test Precision': 97.5609756097561,\n",
       " 'Test Recall': 95.23809523809523,\n",
       " 'Best Params': ''}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_results(\"GBT - default\", model, param_grid, 1, train_x, train_y, test_x, test_y, save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "e229f870623574a0a27c749607e7ae15c7533e1d9cf7e984708c3e1d22efe5a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
